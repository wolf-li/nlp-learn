{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7fe4a04b1e514e778085ab7005ab6cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f919b6b3bb74d2f96cc20a414b22429",
              "IPY_MODEL_f794b4fbd83b4785908c68600b4ad5fd",
              "IPY_MODEL_0cd94292b62140fcb9e8656b9b3099b7"
            ],
            "layout": "IPY_MODEL_2d7f09172b9c49058d00f86825e99dcd"
          }
        },
        "7f919b6b3bb74d2f96cc20a414b22429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce45d118ba17423492362842890063ea",
            "placeholder": "​",
            "style": "IPY_MODEL_a9da9bf4064c48bbb42e109023189b0d",
            "value": "Map: 100%"
          }
        },
        "f794b4fbd83b4785908c68600b4ad5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9f41fc30674bf3b6fce15a6a80e1c7",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91653e22da844d9f9d4c703704cc3afd",
            "value": 10000
          }
        },
        "0cd94292b62140fcb9e8656b9b3099b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cead3e8be1415f9dc96a2dd0a94156",
            "placeholder": "​",
            "style": "IPY_MODEL_179b296e5153403d9fda78f270fff6b9",
            "value": " 10000/10000 [00:02&lt;00:00, 3912.77 examples/s]"
          }
        },
        "2d7f09172b9c49058d00f86825e99dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce45d118ba17423492362842890063ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9da9bf4064c48bbb42e109023189b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff9f41fc30674bf3b6fce15a6a80e1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91653e22da844d9f9d4c703704cc3afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11cead3e8be1415f9dc96a2dd0a94156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179b296e5153403d9fda78f270fff6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 摘要任务\n",
        "参考文章：[huggingface nlp learn summarization](https://huggingface.co/learn/nlp-course/chapter7/5?fw=pt#summarization)\n",
        "## 任务目标:\n",
        "训练一个双语文本摘要模型(英语、西班牙)\n",
        "## 数据集准备\n",
        "Multilingual Amazon Reviews Corpus （amazon 不在提供从其他途径下载到google drive 本地读取）  \n",
        "该语料库由六种语言的亚马逊产品评论组成，通常用于对多语言分类器进行基准测试\n"
      ],
      "metadata": {
        "id": "kLnjwyiH9kIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmOfiVTFYTh8",
        "outputId": "087b1a0a-7b3c-489b-fae6-66ca741d344a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.3-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.3 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "sumDataset = load_dataset('csv', data_files={'train': '/content/drive/MyDrive/MultilingualAmazonReviews/test.csv', 'test': '/content/drive/MyDrive/MultilingualAmazonReviews/validation.csv'})\n",
        "sumDataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StX1VPq9KGsz",
        "outputId": "3099dcb5-04db-4566-a1e3-e567a4e38d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 30000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
              "        num_rows: 30000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enSumTrainDataset = sumDataset['train'].filter(lambda example: example['language'].startswith('en'))\n",
        "print(enSumTrainDataset)\n",
        "enSumTestDataset = sumDataset['test'].filter(lambda example: example['language'].startswith('en'))\n",
        "print(enSumTestDataset)\n",
        "esSumTrainDataset = sumDataset['train'].filter(lambda example: example['language'].startswith('es'))\n",
        "print(esSumTrainDataset)\n",
        "esSumTestDataset = sumDataset['test'].filter(lambda example: example['language'].startswith('es'))\n",
        "print(esSumTestDataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVBzhCM4TNan",
        "outputId": "9097a054-8553-4843-d717-098c214971cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 5000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 5000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 5000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 5000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smTrainDataset = sumDataset['train'].filter(lambda example: example['language'].startswith('en') or example['language'].startswith('es')).shuffle(seed=42)\n",
        "print(smTrainDataset)\n",
        "smTestDataset = sumDataset['test'].filter(lambda example: example['language'].startswith('en') or example['language'].startswith('es')).shuffle(seed=42)\n",
        "print(smTestDataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNM8fqghwm4f",
        "outputId": "ff3a6ec4-d8da-4b71-e3ab-b572586b4f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
            "    num_rows: 10000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看数据"
      ],
      "metadata": {
        "id": "WO6KY52yU0q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_samples(dataset, num_samples=3, seed=42):\n",
        "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
        "    for example in sample:\n",
        "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
        "        print(f\"'>> Review: {example['review_body']}'\")\n",
        "\n",
        "\n",
        "show_samples(sumDataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvY-i957U2UI",
        "outputId": "afb9c729-ae15-4a6a-f19c-9a77be44262f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>> Title: Como dicen otras opiniones, la foto del producto es engañosa.'\n",
            "'>> Review: La madera que aparece en la foto, parece una madera barnizada y bien tratada. La que llega en el paquete es una mala imitación mal tintada, con partes descoloridas donde se ha aplicado mal el tinte. El producto viene desmontado y sin instrucciones de montaje, cuando le pedimos al vendedor que nos envíe un pdf por correo electrónico para montarlo correctamente, nos contesta que ya nos lo enviará y a las 24 horas, manda una mala foto con una flecha (que adjunto), indicando que intentemos montarlo por favor. En resumen, el producto no es como el de la foto, y la atención postventa del vendedor es inexistente. No recomiendo la compra.'\n",
            "\n",
            "'>> Title: Zurfrieden'\n",
            "'>> Review: Funktioniert einwandfrei.Preis ok.Einfache Waage ohne schnick schnack aber genau das wollte ich.Würde die Waage wieder kaufen oder auch weiter empfehlen'\n",
            "\n",
            "'>> Title: Calidad y eficacia con precio ajustado.'\n",
            "'>> Review: Efectivo cumple bien su función'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看评论商品种类信息"
      ],
      "metadata": {
        "id": "Qz-QaVoBVEHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enSumTrainDataset.set_format(\"pandas\")\n",
        "english_df = enSumTrainDataset[:]\n",
        "# Show counts for top 20 products\n",
        "english_df[\"product_category\"].value_counts()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiUX2s39VWxw",
        "outputId": "63cc869a-4801-44e1-cc5b-a96f31104a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "home                      440\n",
              "apparel                   390\n",
              "wireless                  374\n",
              "other                     324\n",
              "beauty                    301\n",
              "drugstore                 289\n",
              "kitchen                   254\n",
              "toy                       241\n",
              "sports                    217\n",
              "automotive                187\n",
              "home_improvement          183\n",
              "digital_ebook_purchase    173\n",
              "lawn_and_garden           173\n",
              "pet_products              168\n",
              "pc                        155\n",
              "electronics               153\n",
              "office_product            139\n",
              "shoes                     129\n",
              "grocery                   115\n",
              "book                      105\n",
              "Name: product_category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型选择，对于多语言可以使用 mT5、mBART-50\n",
        "### 编码器加载"
      ],
      "metadata": {
        "id": "NjECZa3wWecP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# seq2seq tokenizer need sentencepiece pip install it\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDbtBnZmWd76",
        "outputId": "bd5e5529-28ed-47be-b697-d8a43c55b764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt3oXd_PXY1W",
        "outputId": "6792cbe6-723c-4d66-d37a-55a836461f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"I loved reading the Hunger Games!\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5aQpMiwYt5X",
        "outputId": "16bf223d-d090-492f-dd4f-b4ff9a07fcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [336, 259, 28387, 11807, 287, 62893, 295, 12507, 309, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUIut8ZQYxtb",
        "outputId": "91269a64-abcf-42a9-a293-a7ad5102bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁I', '▁', 'loved', '▁reading', '▁the', '▁Hung', 'er', '▁Games', '!', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 30\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"review_body\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "uwCWgxN7ZC0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = smTrainDataset.map(preprocess_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z09Yg-wiZDyt",
        "outputId": "c966dd48-7d7c-4939-f92a-9b87f39a9b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets1 = smTestDataset.map(preprocess_function, batched=True)\n",
        "tokenized_datasets1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "7fe4a04b1e514e778085ab7005ab6cc7",
            "7f919b6b3bb74d2f96cc20a414b22429",
            "f794b4fbd83b4785908c68600b4ad5fd",
            "0cd94292b62140fcb9e8656b9b3099b7",
            "2d7f09172b9c49058d00f86825e99dcd",
            "ce45d118ba17423492362842890063ea",
            "a9da9bf4064c48bbb42e109023189b0d",
            "ff9f41fc30674bf3b6fce15a6a80e1c7",
            "91653e22da844d9f9d4c703704cc3afd",
            "11cead3e8be1415f9dc96a2dd0a94156",
            "179b296e5153403d9fda78f270fff6b9"
          ]
        },
        "id": "dn2ZEEqUMsZb",
        "outputId": "c1b676de-91cc-4ee9-fe65-3c1b91cadd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fe4a04b1e514e778085ab7005ab6cc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "指标评测  \n",
        "ROUGE-L 计算最长公共子序列  \n",
        "ROUGE-N 预测句子按N拆字计算召回率  \n",
        "[参考](https://zhuanlan.zhihu.com/p/504279252)"
      ],
      "metadata": {
        "id": "WHlGQVMxxv91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um1bKIOhxuJb",
        "outputId": "207c7504-3dca-428e-92ba-dbfd19f44279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=e37e87a1a77702c473409be6a5f3fd6069a36a1adcd9c41b51dc3574c86df5c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.0 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "ut_lpJ3R1cVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rouge_score.compute.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMt3Awxo2cB8",
        "outputId": "2437852e-bc0b-47ff-f730-049f44dba4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compute the evaluation module.\n",
            "\n",
            "        Usage of positional arguments is not allowed to prevent mistakes.\n",
            "\n",
            "        Args:\n",
            "            predictions (list/array/tensor, optional): Predictions.\n",
            "            references (list/array/tensor, optional): References.\n",
            "            **kwargs (optional): Keyword arguments that will be forwarded to the evaluation module :meth:`_compute`\n",
            "                method (see details in the docstring).\n",
            "\n",
            "        Return:\n",
            "            dict or None\n",
            "\n",
            "            - Dictionary with the results if this evaluation module is run on the main process (``process_id == 0``).\n",
            "            - None if the evaluation module is not run on the main process (``process_id != 0``).\n",
            "        \n",
            "Calculates average rouge scores for a list of hypotheses and references\n",
            "Args:\n",
            "    predictions: list of predictions to score. Each prediction\n",
            "        should be a string with tokens separated by spaces.\n",
            "    references: list of reference for each prediction. Each\n",
            "        reference should be a string with tokens separated by spaces.\n",
            "    rouge_types: A list of rouge types to calculate.\n",
            "        Valid names:\n",
            "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
            "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
            "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
            "\"`.\n",
            "        See details in https://github.com/huggingface/datasets/issues/617\n",
            "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
            "    use_aggregator: Return aggregates if this is set to True\n",
            "Returns:\n",
            "    rouge1: rouge_1 (f1),\n",
            "    rouge2: rouge_2 (f1),\n",
            "    rougeL: rouge_l (f1),\n",
            "    rougeLsum: rouge_lsum (f1)\n",
            "Examples:\n",
            "\n",
            "    >>> rouge = evaluate.load('rouge')\n",
            "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
            "    >>> references = [\"hello there\", \"general kenobi\"]\n",
            "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
            "    >>> print(results)\n",
            "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
        "reference_summary = \"I loved reading the Hunger Games\"\n",
        "scores = rouge_score.compute(\n",
        "    predictions=[generated_summary], references=[reference_summary]\n",
        ")\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L48ix_Ui19UN",
        "outputId": "bd699033-33d4-4dee-c2e9-55edd753ff65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.923076923076923,\n",
              " 'rouge2': 0.7272727272727272,\n",
              " 'rougeL': 0.923076923076923,\n",
              " 'rougeLsum': 0.923076923076923}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores[\"rouge1\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyXgG1sB2NJR",
        "outputId": "79a35d48-5592-4ba9-a714-51c46596919c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\",model=\"google/mt5-small\")\n",
        "articale = tokenized_datasets[1]['review_body']\n",
        "summarizer(articale, max_length = 30, min_length = 5, do_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omj3VXSg-t0A",
        "outputId": "570e220a-1484-4938-fd94-b4ce1cbe7528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': '<extra_id_0>.) <extra_id_37>.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型"
      ],
      "metadata": {
        "id": "D6p1CxWGFNsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")"
      ],
      "metadata": {
        "id": "kOo5iyBeFNdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义 训练 args\n"
      ],
      "metadata": {
        "id": "xq-PebFeFVQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR1Xn3xsHO5V",
        "outputId": "c51650fa-7698-405d-c8dc-b1bd13b4d060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/244.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 15\n",
        "num_train_epochs = 8\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(tokenized_datasets) // batch_size\n",
        "model_name = \"mt5-small\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-amazon-en-es\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5.6e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=logging_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "uahlvI4hFYZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jE6AwiKmL4YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_JZc7v9MGzz",
        "outputId": "7b4a8340-a3dc-412d-91d1-59c4d7ca67d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myMf59I0MJZ-",
        "outputId": "b7be3bfc-38ce-454a-cc20-00ef7c465d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "def three_sentence_summary(text):\n",
        "    return \"\\n\".join(sent_tokenize(text)[:3])"
      ],
      "metadata": {
        "id": "sp9VBLZYMNPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    # labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract the median scores\n",
        "    result = {key: value.fmeasure * 100 for key, value in result.items()}\n",
        "    return {k: v for k, v in result.items()}"
      ],
      "metadata": {
        "id": "Jdlq4FONL48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "官方文档测试函数"
      ],
      "metadata": {
        "id": "awipUx6pk-aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jgTsjgurnG3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "  preds = [pred.strip() for pred in preds]\n",
        "  labels = [label.strip() for label in labels]\n",
        "\n",
        "  # rougeLSum expects newline after each sentence\n",
        "  preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "  labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "  return preds, labels"
      ],
      "metadata": {
        "id": "OnbvcRcxlDvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  preds, labels = eval_preds\n",
        "  if isinstance(preds, tuple):\n",
        "      preds = preds[0]\n",
        "  # Replace -100s used for padding as we can't decode them\n",
        "  preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
        "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  # Some simple post-processing\n",
        "  decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "  return result"
      ],
      "metadata": {
        "id": "lnoJi54ec7hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "y_LtsPcwL8_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(\n",
        "    enSumTrainDataset.column_names\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QdGUYY8FEs4",
        "outputId": "83a19e01-d924-48f3-e359-2b9982d7c23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets1 = tokenized_datasets1.remove_columns(\n",
        "    enSumTrainDataset.column_names\n",
        ")\n",
        "tokenized_datasets1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "419baXS7M5qm",
        "outputId": "356e5513-d7e4-4e91-aba0-f372808cb88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成 decoder_input_ids 给 decoder 模型使用"
      ],
      "metadata": {
        "id": "jRtNkdmbMc7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [tokenized_datasets[i] for i in range(2)]\n",
        "data_collator(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LUoySLRLfPF",
        "outputId": "4cd1877b-166e-4d92-b725-19b6d9967ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  4295,  11569,  11765,    269,   1694,    263,    262,   3674,    375,\n",
              "           1065,    800,    259,  16679,    260,   4295,    259,   9017,    843,\n",
              "         201592,    263,    260,   1517, 120538,   3371,    361,   7387,    289,\n",
              "          31510,    921,   4358,    269,    658,    738,   9109,    260,      1],\n",
              "        [  4042,   2197,    261,    655,  10937,    299,    262,    261,    375,\n",
              "           8601,  29782,    269,  20283,    870,    260,    653,    259,  15571,\n",
              "            450,    259,    280,    651,  41275,    269,  37568,    260,    443,\n",
              "           1113,    450,  10351,      1,      0,      0,      0,      0,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), 'labels': tensor([[  259, 74978,   674,  1057,  8924,   260,     1],\n",
              "        [18779,   269, 46782,     1,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,   259, 74978,   674,  1057,  8924,   260],\n",
              "        [    0, 18779,   269, 46782,     1,     0,     0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = [tokenized_datasets1[i] for i in range(2)]\n",
        "data_collator(features1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdZ_a-HM_Rm",
        "outputId": "dde67214-378a-4693-f6e3-5d58442137fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   259,  74978,  24476,  29139,    435,    259,  42755,   5289,   6057,\n",
              "            426,    283,  85724,    435,  59891,  13363,    319,    303,    289,\n",
              "          68709,   1225,    260,   4691,   1094,   3861,   2197,    260,    501,\n",
              "            259,  10987,    262, 111507,    362,  17025,    260,      1],\n",
              "        [   303,  54719,    262,    259,    262,    707,    319,  23508,    316,\n",
              "           4497,      1,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[ 1927,  4226,   263, 71399,  1928,   259,   276,   450, 60276,   262,\n",
              "           440,   289,   297, 72392, 12325,     1],\n",
              "        [ 3861,  3663,   878,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,  1927,  4226,   263, 71399,  1928,   259,   276,   450, 60276,\n",
              "           262,   440,   289,   297, 72392, 12325],\n",
              "        [    0,  3861,  3663,   878,     1,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets1,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "gnbRJ6p4MnJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "31Al5ao3OnGg",
        "outputId": "bec8a4ee-4942-4878-d452-c609bc9859b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1335' max='5336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1335/5336 12:40 < 38:01, 1.75 it/s, Epoch 2/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.355800</td>\n",
              "      <td>3.268320</td>\n",
              "      <td>12.375800</td>\n",
              "      <td>5.091300</td>\n",
              "      <td>12.112800</td>\n",
              "      <td>12.139400</td>\n",
              "      <td>6.617800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 23/667 00:08 < 04:21, 2.47 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5336' max='5336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5336/5336 1:11:34, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.355800</td>\n",
              "      <td>3.268320</td>\n",
              "      <td>12.375800</td>\n",
              "      <td>5.091300</td>\n",
              "      <td>12.112800</td>\n",
              "      <td>12.139400</td>\n",
              "      <td>6.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.757800</td>\n",
              "      <td>3.049185</td>\n",
              "      <td>12.616400</td>\n",
              "      <td>5.489700</td>\n",
              "      <td>12.360600</td>\n",
              "      <td>12.368500</td>\n",
              "      <td>7.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.523300</td>\n",
              "      <td>3.016106</td>\n",
              "      <td>12.751100</td>\n",
              "      <td>5.557000</td>\n",
              "      <td>12.514200</td>\n",
              "      <td>12.526700</td>\n",
              "      <td>6.812900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.392100</td>\n",
              "      <td>2.985302</td>\n",
              "      <td>12.982800</td>\n",
              "      <td>5.779000</td>\n",
              "      <td>12.743800</td>\n",
              "      <td>12.766400</td>\n",
              "      <td>7.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.303600</td>\n",
              "      <td>2.975738</td>\n",
              "      <td>13.178000</td>\n",
              "      <td>5.769500</td>\n",
              "      <td>12.940700</td>\n",
              "      <td>12.947700</td>\n",
              "      <td>7.149200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.243600</td>\n",
              "      <td>2.966601</td>\n",
              "      <td>13.420900</td>\n",
              "      <td>6.034600</td>\n",
              "      <td>13.143100</td>\n",
              "      <td>13.167600</td>\n",
              "      <td>7.498500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.215400</td>\n",
              "      <td>2.962067</td>\n",
              "      <td>13.301900</td>\n",
              "      <td>5.983400</td>\n",
              "      <td>13.035700</td>\n",
              "      <td>13.044900</td>\n",
              "      <td>7.360500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.182300</td>\n",
              "      <td>2.963765</td>\n",
              "      <td>13.444100</td>\n",
              "      <td>6.039400</td>\n",
              "      <td>13.172500</td>\n",
              "      <td>13.183600</td>\n",
              "      <td>7.508900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5336, training_loss=3.371467008404825, metrics={'train_runtime': 4295.2618, 'train_samples_per_second': 18.625, 'train_steps_per_second': 1.242, 'total_flos': 1.226322342144e+16, 'train_loss': 3.371467008404825, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "jIg6HGWT5XfM",
        "outputId": "98820a88-e0d1-4656-b16b-0666bcb09e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='667' max='667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [667/667 06:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.9637651443481445,\n",
              " 'eval_rouge1': 13.4441,\n",
              " 'eval_rouge2': 6.0394,\n",
              " 'eval_rougeL': 13.1725,\n",
              " 'eval_rougeLsum': 13.1836,\n",
              " 'eval_gen_len': 7.5089,\n",
              " 'eval_runtime': 386.3548,\n",
              " 'eval_samples_per_second': 25.883,\n",
              " 'eval_steps_per_second': 1.726,\n",
              " 'epoch': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# articale = tokenizer.decode(tokenized_datasets[2]['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gg4ti7PO6lMJ",
        "outputId": "4d4899a0-a088-45fc-9322-2b0c20893e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Worst iPhone charger ever. The charger head broke after used for 5 Times. Terrible quality.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\",model=\"/content/mt5-small-finetuned-amazon-en-es/checkpoint-5000\")\n",
        "articale = \"Worst iPhone charger ever. The charger head broke after used for 5 Times. Terrible quality.\"\n",
        "summarizer(articale, max_length = 30, min_length = 5, do_sample=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZinBrktv6MNz",
        "outputId": "e259e8c8-1f64-41f4-aafa-893a8c35f713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 30, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Great iPhone charger ever.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}