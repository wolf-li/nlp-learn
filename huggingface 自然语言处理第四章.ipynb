{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPajP+T88rvLVP4FGft5Fup"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ä½¿ç”¨è¯„ä»·æŒ‡æ ‡å·¥å…·\n","è®­ç»ƒå’Œæµ‹è¯•æ¨¡åž‹æ—¶å¾€å¾€éœ€è¦è®¡ç®—ä¸åŒçš„è¯„ä»·æŒ‡æ ‡ï¼Œå¦‚æ­£ç¡®çŽ‡ã€æŸ¥å‡†çŽ‡ã€æŸ¥å…¨çŽ‡ã€F1å€¼ç­‰ï¼Œå…·ä½“æŒ‡æ ‡å¾€å¾€å’Œå¤„ç†çš„æ•°æ®å’Œä»»åŠ¡ç±»åž‹æœ‰å…³ã€‚  \n","åˆ†ç±»é—®é¢˜è¯„ä¼°æŒ‡æ ‡ï¼š  \n","- å‡†ç¡®çŽ‡ â€” Accuracy\n","- ç²¾ç¡®çŽ‡ï¼ˆå·®å‡†çŽ‡ï¼‰- Precision\n","- å¬å›žçŽ‡ï¼ˆæŸ¥å…¨çŽ‡ï¼‰- Recall\n","- F1åˆ†æ•°\n","- ROCæ›²çº¿\n","- AUCæ›²çº¿  \n","\n","å›žå½’é—®é¢˜è¯„ä¼°æŒ‡æ ‡ï¼š\n","- MAE\n","- MSE\n","\n","huggingface æä¾›äº†è¯„ä»·æŒ‡æ ‡å·¥å…·ï¼Œè®¡ç®—ç»“æžœéšè—ã€‚\n","## 1. ä½¿ç”¨è¯„ä»·æŒ‡æ ‡å·¥å…·\n","### 1. åˆ—å‡ºå¯ç”¨çš„è¯„ä»·æŒ‡æ ‡\n","ä½¿ç”¨ list_metrics() å‡½æ•°åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯„ä»·æŒ‡æ ‡"],"metadata":{"id":"6nsN_tpPoMoR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKKEugdKn_4V","executionInfo":{"status":"ok","timestamp":1690970893247,"user_tz":-480,"elapsed":14895,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"c823d1c4-bced-4cf9-ffdb-0d6c62645535"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.14.2 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 xxhash-3.3.0\n"]}],"source":["# !pip install datasets"]},{"cell_type":"code","source":["from datasets import list_metrics\n","metrics_list = list_metrics()\n","len(metrics_list), metrics_list[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2cFJOqauLa9","executionInfo":{"status":"ok","timestamp":1690970977877,"user_tz":-480,"elapsed":511,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"cc87ff97-f4df-46e2-d7ff-17bfdfbab203"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-0404ed0be804>:2: FutureWarning: list_metrics is deprecated and will be removed in the next major version of datasets. Use 'evaluate.list_evaluation_modules' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metrics_list = list_metrics()\n"]},{"output_type":"execute_result","data":{"text/plain":["(121, ['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score'])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### 2. åŠ è½½ä¸€ä¸ªè¯„ä»·æŒ‡æ ‡\n","åˆ©ç”¨ load_metric() å‡½æ•°ï¼Œè¯„ä»·æŒ‡æ ‡å¾€å¾€ä¼šå¯¹åº”çš„æ•°æ®é›†é…å¥—ä½¿ç”¨ï¼Œä¸‹é¢ä»¥ glue æ•°æ®é›†çš„ mrpc å­é›†ä½ä¾‹:  \n","æ³¨æ„å¹¶ä¸æ˜¯æ¯ä¸€ä¸ªæ•°æ®é›†éƒ½æœ‰è¯„ä»·æŒ‡æ ‡ï¼Œå®žé™…åº”ç”¨æ—¶åº”æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©åˆé€‚çš„è¯„ä»·æŒ‡æ ‡ã€‚"],"metadata":{"id":"x3pppiOnu1ve"}},{"cell_type":"code","source":["from datasets import load_metric\n","metric = load_metric('glue','mrpc')\n","print(metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY_J1SHjvWNm","executionInfo":{"status":"ok","timestamp":1690972274095,"user_tz":-480,"elapsed":1444,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"97621446-b56a-4119-96e7-a805650a9451"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n","Compute GLUE evaluation metric associated to each GLUE dataset.\n","Args:\n","    predictions: list of predictions to score.\n","        Each translation should be tokenized into a list of tokens.\n","    references: list of lists of references for each translation.\n","        Each reference should be tokenized into a list of tokens.\n","Returns: depending on the GLUE subset, one or several of:\n","    \"accuracy\": Accuracy\n","    \"f1\": F1 score\n","    \"pearson\": Pearson Correlation\n","    \"spearmanr\": Spearman Correlation\n","    \"matthews_correlation\": Matthew Correlation\n","Examples:\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0, 'f1': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n","    >>> references = [0., 1., 2., 3., 4., 5.]\n","    >>> predictions = [0., 1., 2., 3., 4., 5.]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n","    {'pearson': 1.0, 'spearmanr': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'cola')\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'matthews_correlation': 1.0}\n","\"\"\", stored examples: 0)\n"]}]},{"cell_type":"markdown","source":["### 3. èŽ·å–è¯„ä»·æŒ‡æ ‡çš„ä½¿ç”¨è¯´æ˜Ž\n","è¯„ä»·æŒ‡æ ‡çš„ inputs_description å±žæ€§ä¸ºä¸€æ®µæ–‡æœ¬ï¼Œæè¿°è¯„ä»·æŒ‡æ ‡çš„ä½¿ç”¨æ–¹æ³•ï¼Œä¸åŒçš„è¯„ä»·æŒ‡æ ‡è¾“å…¥å¾€å¾€æ˜¯ä¸åŒçš„ã€‚"],"metadata":{"id":"aHO-WwIvuI7Z"}},{"cell_type":"code","source":["print(metric.inputs_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXgjhJ5-0CHI","executionInfo":{"status":"ok","timestamp":1690972497138,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"6f9d054d-a813-43f5-e265-b5693a0d60e4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Compute GLUE evaluation metric associated to each GLUE dataset.\n","Args:\n","    predictions: list of predictions to score.\n","        Each translation should be tokenized into a list of tokens.\n","    references: list of lists of references for each translation.\n","        Each reference should be tokenized into a list of tokens.\n","Returns: depending on the GLUE subset, one or several of:\n","    \"accuracy\": Accuracy\n","    \"f1\": F1 score\n","    \"pearson\": Pearson Correlation\n","    \"spearmanr\": Spearman Correlation\n","    \"matthews_correlation\": Matthew Correlation\n","Examples:\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0, 'f1': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n","    >>> references = [0., 1., 2., 3., 4., 5.]\n","    >>> predictions = [0., 1., 2., 3., 4., 5.]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n","    {'pearson': 1.0, 'spearmanr': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'cola')\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'matthews_correlation': 1.0}\n","\n"]}]},{"cell_type":"markdown","source":["### 4. è®¡ç®—è¯„ä»·æŒ‡æ ‡\n"],"metadata":{"id":"YWp7oXP20tsX"}},{"cell_type":"code","source":["glue_metric = load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","references = [0, 1, 0, 1]  # æ ‡è®°\n","predictions = [0, 1, 1, 0]  # æ¨¡åž‹é¢„æµ‹ç»“æžœ\n","results = glue_metric.compute(predictions=predictions, references=references)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hM0R0LF02xF","executionInfo":{"status":"ok","timestamp":1690972799897,"user_tz":-480,"elapsed":1583,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"2d25bff2-d0b4-49c5-d182-2b67c39a4481"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.5, 'f1': 0.5}\n"]}]}]}