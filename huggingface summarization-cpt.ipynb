{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ldHZmZTIRzC_o9aou8QWZI-L9-W5VHjg","authorship_tag":"ABX9TyN+WiX4IMhNKR97iZeGrA4h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5704b8de2a4d4db78ea59a6301369312":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89df2097e0d447ac93c9a6e3b6e71f78","IPY_MODEL_f395d15f2bbe40f09e52c38c0459c8a0","IPY_MODEL_5f052f02014e4d47b6971c95a332e056"],"layout":"IPY_MODEL_725f40056bb64fdfae03bf9790e50a45"}},"89df2097e0d447ac93c9a6e3b6e71f78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf6cc9f08ed642f0a616918a7ecc1227","placeholder":"​","style":"IPY_MODEL_53c5cf9f2bf44e49b3ec9936763e265d","value":"Map: 100%"}},"f395d15f2bbe40f09e52c38c0459c8a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c976a8e6c72b4e5fa4a92f35df55de26","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8345b7032f844089906fa2abe1238d9","value":5000}},"5f052f02014e4d47b6971c95a332e056":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b32e90a6b4c405eb46fb5301096e73f","placeholder":"​","style":"IPY_MODEL_f1a541d4747c496f998c17cea0bd132f","value":" 5000/5000 [00:02&lt;00:00, 1883.06 examples/s]"}},"725f40056bb64fdfae03bf9790e50a45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf6cc9f08ed642f0a616918a7ecc1227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c5cf9f2bf44e49b3ec9936763e265d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c976a8e6c72b4e5fa4a92f35df55de26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8345b7032f844089906fa2abe1238d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b32e90a6b4c405eb46fb5301096e73f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a541d4747c496f998c17cea0bd132f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 摘要任务\n","参考文章：[huggingface nlp learn summarization](https://huggingface.co/learn/nlp-course/chapter7/5?fw=pt#summarization)\n","## 任务目标:\n","训练一个双语文本摘要模型(英语、西班牙)\n","## 数据集准备\n","Multilingual Amazon Reviews Corpus （amazon 不在提供从其他途径下载到google drive 本地读取）  \n","该语料库由六种语言的亚马逊产品评论组成，通常用于对多语言分类器进行基准测试  \n","English(en), Japanese(ja), German(de), French(fr), Chinese(zh) and Spanish(es).\n"],"metadata":{"id":"kLnjwyiH9kIO"}},{"cell_type":"code","source":["!pip install sentencepiece\n","!pip install transformers\n","!pip install datasets\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmOfiVTFYTh8","executionInfo":{"status":"ok","timestamp":1691546198544,"user_tz":-480,"elapsed":35034,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"7782d92d-f67f-4850-acb1-e1628c554918"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","sumDataset = load_dataset('csv', data_files={'train': '/content/drive/MyDrive/MultilingualAmazonReviews/test.csv', 'test': '/content/drive/MyDrive/MultilingualAmazonReviews/validation.csv'})\n","sumDataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StX1VPq9KGsz","executionInfo":{"status":"ok","timestamp":1691546548314,"user_tz":-480,"elapsed":1750,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"c53c521c-6d6a-4bb6-af88-6bc8220ac626"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 30000\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","        num_rows: 30000\n","    })\n","})"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["zhSumTrainDataset = sumDataset['train'].filter(lambda example: example['language'].startswith('zh'))\n","print(zhSumTrainDataset)\n","zhSumTestDataset = sumDataset['test'].filter(lambda example: example['language'].startswith('zh'))\n","print(zhSumTestDataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVBzhCM4TNan","executionInfo":{"status":"ok","timestamp":1691546548314,"user_tz":-480,"elapsed":7,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"5fbff637-a9aa-44a6-c0aa-480b5d7bf5d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","    num_rows: 5000\n","})\n","Dataset({\n","    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n","    num_rows: 5000\n","})\n"]}]},{"cell_type":"markdown","source":["查看数据"],"metadata":{"id":"WO6KY52yU0q_"}},{"cell_type":"code","source":["def show_samples(dataset, num_samples=3, seed=42):\n","    sample = dataset[\"train\"].shuffle(seed=seed).filter(lambda example: example['language'].startswith('zh')).select(range(num_samples))\n","    for example in sample:\n","        print(f\"\\n'>> Title: {example['review_title']}'\")\n","        print(f\"'>> Review: {example['review_body']}'\")\n","\n","\n","show_samples(sumDataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvY-i957U2UI","executionInfo":{"status":"ok","timestamp":1691546549119,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"9f94016a-4eb6-4668-a55d-69100d86578a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","'>> Title: 简单方便 性价比高'\n","'>> Review: 有奶碟方便很多，傻瓜操作；costa的胶囊会好喝些......已经陆续买了三台............'\n","\n","'>> Title: 还可以'\n","'>> Review: 想吃麦片，看评论很多说这个好，买的，麦片和其他也差不多'\n","\n","'>> Title: 不错'\n","'>> Review: 基本信息都全，没去过的地方纸上先去一下。'\n"]}]},{"cell_type":"markdown","source":["查看评论商品种类信息"],"metadata":{"id":"Qz-QaVoBVEHA"}},{"cell_type":"code","source":["zhSumTrainDataset.set_format(\"pandas\")\n","english_df = zhSumTrainDataset[:]\n","# Show counts for top 20 products\n","english_df[\"product_category\"].value_counts()[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PiUX2s39VWxw","executionInfo":{"status":"ok","timestamp":1691546550619,"user_tz":-480,"elapsed":2,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"d9ae4f65-14d1-4336-92f5-4c5d11f64543"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["book                      1567\n","digital_ebook_purchase     458\n","apparel                    308\n","shoes                      236\n","beauty                     224\n","kitchen                    223\n","other                      212\n","home                       190\n","grocery                    186\n","wireless                   173\n","drugstore                  169\n","baby_product               161\n","sports                     132\n","pc                         130\n","watch                       97\n","toy                         93\n","home_improvement            84\n","electronics                 73\n","office_product              72\n","luggage                     72\n","Name: product_category, dtype: int64"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["zhSumTrainDataset.reset_format()"],"metadata":{"id":"hAxQ6dCBxXjr","executionInfo":{"status":"ok","timestamp":1691546552527,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["模型选择，对于多语言可以使用 mT5、mBART-50、fnlp/bart-base-chinese\n","### 编码器加载"],"metadata":{"id":"NjECZa3wWecP"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","# seq2seq tokenizer need sentencepiece pip install it\n","check_model = \"fnlp/cpt-base\"\n","tokenizer = AutoTokenizer.from_pretrained(check_model)"],"metadata":{"id":"uDbtBnZmWd76","executionInfo":{"status":"ok","timestamp":1691546554492,"user_tz":-480,"elapsed":1550,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["tokenizer.pad_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wt3oXd_PXY1W","executionInfo":{"status":"ok","timestamp":1691542245738,"user_tz":-480,"elapsed":2,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"c25bbb9a-ccbc-4725-9424-e052e11cd378"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["inputs = tokenizer(\"想吃麦片\")\n","inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5aQpMiwYt5X","executionInfo":{"status":"ok","timestamp":1691546555927,"user_tz":-480,"elapsed":7,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"3485dbee-0947-460d-f02f-ecba79ed940f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 9688, 6422, 25184, 14062, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["tokenizer.convert_ids_to_tokens(inputs.input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUIut8ZQYxtb","executionInfo":{"status":"ok","timestamp":1691546557596,"user_tz":-480,"elapsed":2,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"41216d64-8f57-41b8-f379-8c5af06f787c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]', '想', '吃', '麦', '片', '[SEP]']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["max_input_length = 512\n","max_target_length = 70\n","\n","\n","def preprocess_function(examples):\n","    model_inputs = tokenizer(\n","        examples[\"review_body\"],\n","        max_length=max_input_length,\n","        truncation=True,\n","    )\n","    labels = tokenizer(\n","        examples[\"review_title\"], max_length=max_target_length, truncation=True\n","    )\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"metadata":{"id":"uwCWgxN7ZC0f","executionInfo":{"status":"ok","timestamp":1691546558327,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = zhSumTrainDataset.map(preprocess_function, batched=True)\n","tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["5704b8de2a4d4db78ea59a6301369312","89df2097e0d447ac93c9a6e3b6e71f78","f395d15f2bbe40f09e52c38c0459c8a0","5f052f02014e4d47b6971c95a332e056","725f40056bb64fdfae03bf9790e50a45","bf6cc9f08ed642f0a616918a7ecc1227","53c5cf9f2bf44e49b3ec9936763e265d","c976a8e6c72b4e5fa4a92f35df55de26","d8345b7032f844089906fa2abe1238d9","0b32e90a6b4c405eb46fb5301096e73f","f1a541d4747c496f998c17cea0bd132f"]},"id":"z09Yg-wiZDyt","executionInfo":{"status":"ok","timestamp":1691546561233,"user_tz":-480,"elapsed":2413,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"bddab54b-3214-4cd9-ea69-3c98ac93a226"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5704b8de2a4d4db78ea59a6301369312"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 5000\n","})"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["tokenized_datasets1 = zhSumTestDataset.map(preprocess_function, batched=True)\n","tokenized_datasets1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn2ZEEqUMsZb","executionInfo":{"status":"ok","timestamp":1691546561234,"user_tz":-480,"elapsed":5,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"4678a202-ea78-49ba-873c-1d1da7de927a"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 5000\n","})"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["指标评测  \n","ROUGE-L 计算最长公共子序列  \n","ROUGE-N 预测句子按N拆字计算召回率  \n","[参考](https://zhuanlan.zhihu.com/p/504279252)"],"metadata":{"id":"WHlGQVMxxv91"}},{"cell_type":"code","source":["!pip install rouge_score\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"um1bKIOhxuJb","executionInfo":{"status":"ok","timestamp":1691546353458,"user_tz":-480,"elapsed":26768,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"e19b0e90-6157-42d4-bf2c-0c9da7a83255"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"]}]},{"cell_type":"code","source":["import evaluate\n","rouge_score = evaluate.load(\"rouge\")"],"metadata":{"id":"ut_lpJ3R1cVU","executionInfo":{"status":"ok","timestamp":1691546575916,"user_tz":-480,"elapsed":12932,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(rouge_score.compute.__doc__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMt3Awxo2cB8","executionInfo":{"status":"ok","timestamp":1691546575916,"user_tz":-480,"elapsed":42,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"b2026307-3551-4a07-8376-8418fdab7a4a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Compute the evaluation module.\n","\n","        Usage of positional arguments is not allowed to prevent mistakes.\n","\n","        Args:\n","            predictions (list/array/tensor, optional): Predictions.\n","            references (list/array/tensor, optional): References.\n","            **kwargs (optional): Keyword arguments that will be forwarded to the evaluation module :meth:`_compute`\n","                method (see details in the docstring).\n","\n","        Return:\n","            dict or None\n","\n","            - Dictionary with the results if this evaluation module is run on the main process (``process_id == 0``).\n","            - None if the evaluation module is not run on the main process (``process_id != 0``).\n","        \n","Calculates average rouge scores for a list of hypotheses and references\n","Args:\n","    predictions: list of predictions to score. Each prediction\n","        should be a string with tokens separated by spaces.\n","    references: list of reference for each prediction. Each\n","        reference should be a string with tokens separated by spaces.\n","    rouge_types: A list of rouge types to calculate.\n","        Valid names:\n","        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n","        `\"rougeL\"`: Longest common subsequence based scoring.\n","        `\"rougeLsum\"`: rougeLsum splits text using `\"\n","\"`.\n","        See details in https://github.com/huggingface/datasets/issues/617\n","    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n","    use_aggregator: Return aggregates if this is set to True\n","Returns:\n","    rouge1: rouge_1 (f1),\n","    rouge2: rouge_2 (f1),\n","    rougeL: rouge_l (f1),\n","    rougeLsum: rouge_lsum (f1)\n","Examples:\n","\n","    >>> rouge = evaluate.load('rouge')\n","    >>> predictions = [\"hello there\", \"general kenobi\"]\n","    >>> references = [\"hello there\", \"general kenobi\"]\n","    >>> results = rouge.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n","\n"]}]},{"cell_type":"code","source":["generated_summary = \"简单方便 性价比高\"\n","reference_summary = \"简单，划算\"\n","scores = rouge_score.compute(\n","    predictions=[generated_summary], references=[reference_summary]\n",")\n","scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L48ix_Ui19UN","executionInfo":{"status":"ok","timestamp":1691546576344,"user_tz":-480,"elapsed":431,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"2b29f029-c52f-41cf-9bc4-c84d92d52411"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["scores[\"rouge1\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyXgG1sB2NJR","executionInfo":{"status":"ok","timestamp":1691542664776,"user_tz":-480,"elapsed":299,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"cf695e80-0aa6-4dba-9ecd-7b0541cd03c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from transformers import pipeline\n","summarizer = pipeline(\"summarization\",model=check_model)\n","# articale = tokenized_datasets[1]['review_body']\n","artocale ='''本文总结了十个可穿戴产品的设计原则，而这些原则，同样也是笔者认为是这个行业最吸引人的地方：1.为人们解决重复性问题；2.从人开始，而不是从机器开始；3.要引起注意，但不要刻意；4.提升用户能力，而不是取代人'''\n","print(artocale)\n","summarizer(artocale, max_length = 30, min_length = 5, do_sample=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Omj3VXSg-t0A","executionInfo":{"status":"ok","timestamp":1691550542466,"user_tz":-480,"elapsed":10280,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"2c91e5ef-1a3b-4716-c7df-3eb0cbb8feba"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at fnlp/cpt-base were not used when initializing BartForConditionalGeneration: ['model.encoder.encoder.layer.4.attention.self.value.weight', 'model.encoder.encoder.layer.11.attention.self.query.weight', 'model.encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.1.attention.self.query.bias', 'model.encoder.encoder.layer.8.output.LayerNorm.bias', 'model.encoder.encoder.layer.2.intermediate.dense.weight', 'model.encoder.encoder.layer.1.output.dense.bias', 'model.encoder.encoder.layer.3.attention.self.value.weight', 'model.encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.2.attention.self.value.bias', 'model.encoder.encoder.layer.5.intermediate.dense.bias', 'model.encoder.encoder.layer.5.output.dense.weight', 'model.encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.5.attention.self.query.bias', 'model.encoder.encoder.layer.6.output.LayerNorm.bias', 'model.encoder.encoder.layer.4.attention.self.query.weight', 'model.encoder.encoder.layer.1.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.output.dense.bias', 'model.encoder.encoder.layer.11.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.intermediate.dense.weight', 'model.encoder.encoder.layer.11.output.LayerNorm.bias', 'model.encoder.encoder.layer.11.intermediate.dense.bias', 'model.encoder.encoder.layer.2.attention.self.query.bias', 'model.encoder.encoder.layer.6.output.dense.bias', 'model.encoder.encoder.layer.1.attention.output.dense.bias', 'model.encoder.encoder.layer.6.intermediate.dense.weight', 'model.encoder.embeddings.LayerNorm.weight', 'model.encoder.encoder.layer.6.intermediate.dense.bias', 'model.encoder.encoder.layer.8.output.dense.bias', 'model.encoder.encoder.layer.7.attention.self.value.bias', 'model.encoder.encoder.layer.0.attention.self.value.bias', 'model.encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.key.bias', 'model.encoder.encoder.layer.1.intermediate.dense.bias', 'model.encoder.encoder.layer.3.output.dense.bias', 'model.encoder.encoder.layer.7.attention.output.dense.weight', 'model.encoder.encoder.layer.10.attention.output.dense.bias', 'model.encoder.embeddings.token_type_embeddings.weight', 'model.encoder.encoder.layer.1.attention.self.key.bias', 'model.encoder.encoder.layer.8.intermediate.dense.weight', 'model.encoder.encoder.layer.1.output.dense.weight', 'model.encoder.encoder.layer.7.attention.self.query.weight', 'model.encoder.encoder.layer.2.attention.self.key.bias', 'model.encoder.encoder.layer.3.intermediate.dense.bias', 'model.encoder.encoder.layer.8.intermediate.dense.bias', 'model.encoder.encoder.layer.10.attention.self.query.weight', 'model.encoder.encoder.layer.0.attention.self.value.weight', 'model.encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.attention.self.key.bias', 'model.encoder.encoder.layer.0.intermediate.dense.weight', 'model.encoder.encoder.layer.7.output.LayerNorm.bias', 'model.encoder.encoder.layer.10.intermediate.dense.weight', 'model.encoder.encoder.layer.2.attention.self.query.weight', 'model.encoder.encoder.layer.9.attention.self.value.bias', 'model.encoder.encoder.layer.7.attention.self.key.weight', 'model.encoder.encoder.layer.8.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.self.key.bias', 'model.encoder.encoder.layer.1.intermediate.dense.weight', 'model.encoder.encoder.layer.3.attention.output.dense.weight', 'model.encoder.encoder.layer.3.attention.self.value.bias', 'model.encoder.encoder.layer.4.attention.self.query.bias', 'model.encoder.encoder.layer.10.output.dense.bias', 'model.encoder.encoder.layer.4.attention.output.dense.weight', 'model.encoder.encoder.layer.6.attention.self.key.bias', 'model.encoder.encoder.layer.7.attention.self.query.bias', 'model.encoder.encoder.layer.5.output.LayerNorm.bias', 'model.encoder.encoder.layer.8.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.value.weight', 'model.encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.output.dense.bias', 'model.encoder.encoder.layer.9.attention.self.query.bias', 'model.encoder.encoder.layer.3.attention.self.key.weight', 'model.encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.intermediate.dense.bias', 'model.encoder.encoder.layer.9.output.LayerNorm.weight', 'model.encoder.encoder.layer.4.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.output.dense.bias', 'model.encoder.embeddings.word_embeddings.weight', 'model.encoder.encoder.layer.4.attention.output.dense.bias', 'model.encoder.encoder.layer.5.intermediate.dense.weight', 'model.encoder.encoder.layer.11.attention.self.value.bias', 'model.encoder.encoder.layer.0.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.attention.output.dense.bias', 'model.encoder.encoder.layer.3.output.dense.weight', 'model.encoder.encoder.layer.4.output.dense.bias', 'model.encoder.encoder.layer.5.attention.self.query.weight', 'model.encoder.encoder.layer.7.attention.self.value.weight', 'model.encoder.encoder.layer.8.output.dense.weight', 'model.encoder.encoder.layer.11.intermediate.dense.weight', 'model.encoder.encoder.layer.11.output.dense.bias', 'model.encoder.encoder.layer.5.attention.output.dense.weight', 'model.encoder.encoder.layer.4.output.dense.weight', 'model.encoder.encoder.layer.7.output.LayerNorm.weight', 'model.encoder.encoder.layer.0.attention.output.dense.bias', 'model.encoder.encoder.layer.2.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.self.value.weight', 'model.encoder.encoder.layer.1.attention.self.query.weight', 'model.encoder.encoder.layer.6.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.3.attention.self.query.bias', 'model.encoder.encoder.layer.11.attention.output.dense.weight', 'model.encoder.encoder.layer.11.attention.self.key.weight', 'model.encoder.encoder.layer.10.attention.self.query.bias', 'model.encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.output.dense.weight', 'model.encoder.encoder.layer.11.attention.output.dense.bias', 'model.encoder.encoder.layer.2.intermediate.dense.bias', 'model.encoder.embeddings.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.self.query.weight', 'model.encoder.encoder.layer.0.output.dense.bias', 'model.encoder.encoder.layer.2.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.value.weight', 'model.encoder.encoder.layer.6.attention.self.query.bias', 'model.encoder.encoder.layer.11.attention.self.query.bias', 'model.encoder.encoder.layer.0.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.5.output.dense.bias', 'model.encoder.encoder.layer.4.attention.self.key.bias', 'model.encoder.encoder.layer.6.attention.output.dense.weight', 'model.encoder.encoder.layer.9.attention.self.key.weight', 'model.encoder.encoder.layer.0.intermediate.dense.bias', 'model.encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.key.weight', 'model.encoder.encoder.layer.5.attention.self.key.weight', 'model.encoder.encoder.layer.6.attention.self.value.bias', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.intermediate.dense.bias', 'model.encoder.encoder.layer.5.output.LayerNorm.weight', 'model.encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.4.intermediate.dense.weight', 'model.encoder.encoder.layer.1.attention.output.dense.weight', 'model.encoder.encoder.layer.9.output.dense.bias', 'model.encoder.encoder.layer.7.intermediate.dense.weight', 'model.encoder.encoder.layer.4.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.self.key.weight', 'model.encoder.encoder.layer.0.attention.output.dense.weight', 'model.encoder.encoder.layer.1.attention.self.value.weight', 'model.encoder.encoder.layer.1.attention.self.key.weight', 'model.encoder.encoder.layer.0.attention.self.key.weight', 'model.encoder.encoder.layer.2.attention.self.key.weight', 'model.encoder.encoder.layer.4.attention.self.key.weight', 'model.encoder.encoder.layer.11.attention.self.key.bias', 'model.encoder.encoder.layer.6.attention.self.key.weight', 'model.encoder.encoder.layer.3.attention.output.dense.bias', 'model.encoder.embeddings.position_embeddings.weight', 'model.encoder.encoder.layer.1.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.output.dense.weight', 'model.encoder.encoder.layer.7.attention.self.key.bias', 'model.encoder.encoder.layer.0.attention.self.key.bias', 'model.encoder.encoder.layer.9.output.dense.weight', 'model.encoder.encoder.layer.3.attention.self.key.bias', 'model.encoder.encoder.layer.2.attention.output.dense.weight', 'model.encoder.encoder.layer.9.attention.self.value.weight', 'model.encoder.encoder.layer.10.output.LayerNorm.bias', 'model.encoder.encoder.layer.8.attention.self.query.weight', 'model.encoder.encoder.layer.9.attention.self.query.weight', 'model.encoder.encoder.layer.11.output.dense.weight', 'model.encoder.encoder.layer.3.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.query.bias', 'model.encoder.encoder.layer.8.attention.output.dense.weight', 'model.encoder.encoder.layer.4.intermediate.dense.bias', 'model.encoder.encoder.layer.9.attention.output.dense.weight', 'model.encoder.encoder.layer.2.output.dense.bias', 'model.encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.intermediate.dense.bias', 'model.encoder.encoder.layer.0.attention.self.query.weight', 'model.encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.output.dense.weight', 'model.encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.10.attention.self.value.bias', 'model.encoder.encoder.layer.5.attention.output.dense.bias', 'model.encoder.encoder.layer.2.attention.output.dense.bias', 'model.encoder.encoder.layer.3.output.LayerNorm.bias', 'model.encoder.embeddings.position_ids', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.0.output.dense.weight', 'model.encoder.encoder.layer.1.output.LayerNorm.bias', 'model.encoder.encoder.layer.3.attention.self.query.weight', 'model.encoder.encoder.layer.11.attention.self.value.weight', 'model.encoder.encoder.layer.7.output.dense.weight', 'model.encoder.encoder.layer.4.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.value.bias', 'model.encoder.encoder.layer.2.attention.self.value.weight', 'model.encoder.encoder.layer.10.output.dense.weight', 'model.encoder.encoder.layer.0.attention.self.query.bias', 'model.encoder.encoder.layer.3.intermediate.dense.weight', 'model.encoder.encoder.layer.10.attention.self.value.weight', 'model.encoder.encoder.layer.8.attention.self.key.bias', 'model.encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.7.attention.output.dense.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at fnlp/cpt-base and are newly initialized: ['model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.7.final_layer_norm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["本文总结了十个可穿戴产品的设计原则，而这些原则，同样也是笔者认为是这个行业最吸引人的地方：1.为人们解决重复性问题；2.从人开始，而不是从机器开始；3.要引起注意，但不要刻意；4.提升用户能力，而不是取代人\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'summary_text': '多 了 很 多 ， 但 是 很 多 了 多 了 以 后 多 了 ， 多 了 但 是 多 了 电 多 了 。'}]"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["模型"],"metadata":{"id":"D6p1CxWGFNsG"}},{"cell_type":"code","source":["from transformers import AutoModelForSeq2SeqLM\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(check_model)"],"metadata":{"id":"kOo5iyBeFNdW","executionInfo":{"status":"ok","timestamp":1691546591040,"user_tz":-480,"elapsed":3570,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"efed5ffc-19e3-4259-8510-d001507658bc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at fnlp/cpt-base were not used when initializing BartForConditionalGeneration: ['model.encoder.encoder.layer.4.attention.self.value.weight', 'model.encoder.encoder.layer.11.attention.self.query.weight', 'model.encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.1.attention.self.query.bias', 'model.encoder.encoder.layer.8.output.LayerNorm.bias', 'model.encoder.encoder.layer.2.intermediate.dense.weight', 'model.encoder.encoder.layer.1.output.dense.bias', 'model.encoder.encoder.layer.3.attention.self.value.weight', 'model.encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.2.attention.self.value.bias', 'model.encoder.encoder.layer.5.intermediate.dense.bias', 'model.encoder.encoder.layer.5.output.dense.weight', 'model.encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.5.attention.self.query.bias', 'model.encoder.encoder.layer.6.output.LayerNorm.bias', 'model.encoder.encoder.layer.4.attention.self.query.weight', 'model.encoder.encoder.layer.1.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.output.dense.bias', 'model.encoder.encoder.layer.11.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.intermediate.dense.weight', 'model.encoder.encoder.layer.11.output.LayerNorm.bias', 'model.encoder.encoder.layer.11.intermediate.dense.bias', 'model.encoder.encoder.layer.2.attention.self.query.bias', 'model.encoder.encoder.layer.6.output.dense.bias', 'model.encoder.encoder.layer.1.attention.output.dense.bias', 'model.encoder.encoder.layer.6.intermediate.dense.weight', 'model.encoder.embeddings.LayerNorm.weight', 'model.encoder.encoder.layer.6.intermediate.dense.bias', 'model.encoder.encoder.layer.8.output.dense.bias', 'model.encoder.encoder.layer.7.attention.self.value.bias', 'model.encoder.encoder.layer.0.attention.self.value.bias', 'model.encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.key.bias', 'model.encoder.encoder.layer.1.intermediate.dense.bias', 'model.encoder.encoder.layer.3.output.dense.bias', 'model.encoder.encoder.layer.7.attention.output.dense.weight', 'model.encoder.encoder.layer.10.attention.output.dense.bias', 'model.encoder.embeddings.token_type_embeddings.weight', 'model.encoder.encoder.layer.1.attention.self.key.bias', 'model.encoder.encoder.layer.8.intermediate.dense.weight', 'model.encoder.encoder.layer.1.output.dense.weight', 'model.encoder.encoder.layer.7.attention.self.query.weight', 'model.encoder.encoder.layer.2.attention.self.key.bias', 'model.encoder.encoder.layer.3.intermediate.dense.bias', 'model.encoder.encoder.layer.8.intermediate.dense.bias', 'model.encoder.encoder.layer.10.attention.self.query.weight', 'model.encoder.encoder.layer.0.attention.self.value.weight', 'model.encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.attention.self.key.bias', 'model.encoder.encoder.layer.0.intermediate.dense.weight', 'model.encoder.encoder.layer.7.output.LayerNorm.bias', 'model.encoder.encoder.layer.10.intermediate.dense.weight', 'model.encoder.encoder.layer.2.attention.self.query.weight', 'model.encoder.encoder.layer.9.attention.self.value.bias', 'model.encoder.encoder.layer.7.attention.self.key.weight', 'model.encoder.encoder.layer.8.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.self.key.bias', 'model.encoder.encoder.layer.1.intermediate.dense.weight', 'model.encoder.encoder.layer.3.attention.output.dense.weight', 'model.encoder.encoder.layer.3.attention.self.value.bias', 'model.encoder.encoder.layer.4.attention.self.query.bias', 'model.encoder.encoder.layer.10.output.dense.bias', 'model.encoder.encoder.layer.4.attention.output.dense.weight', 'model.encoder.encoder.layer.6.attention.self.key.bias', 'model.encoder.encoder.layer.7.attention.self.query.bias', 'model.encoder.encoder.layer.5.output.LayerNorm.bias', 'model.encoder.encoder.layer.8.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.value.weight', 'model.encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.output.dense.bias', 'model.encoder.encoder.layer.9.attention.self.query.bias', 'model.encoder.encoder.layer.3.attention.self.key.weight', 'model.encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.intermediate.dense.bias', 'model.encoder.encoder.layer.9.output.LayerNorm.weight', 'model.encoder.encoder.layer.4.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.output.dense.bias', 'model.encoder.embeddings.word_embeddings.weight', 'model.encoder.encoder.layer.4.attention.output.dense.bias', 'model.encoder.encoder.layer.5.intermediate.dense.weight', 'model.encoder.encoder.layer.11.attention.self.value.bias', 'model.encoder.encoder.layer.0.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.attention.output.dense.bias', 'model.encoder.encoder.layer.3.output.dense.weight', 'model.encoder.encoder.layer.4.output.dense.bias', 'model.encoder.encoder.layer.5.attention.self.query.weight', 'model.encoder.encoder.layer.7.attention.self.value.weight', 'model.encoder.encoder.layer.8.output.dense.weight', 'model.encoder.encoder.layer.11.intermediate.dense.weight', 'model.encoder.encoder.layer.11.output.dense.bias', 'model.encoder.encoder.layer.5.attention.output.dense.weight', 'model.encoder.encoder.layer.4.output.dense.weight', 'model.encoder.encoder.layer.7.output.LayerNorm.weight', 'model.encoder.encoder.layer.0.attention.output.dense.bias', 'model.encoder.encoder.layer.2.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.self.value.weight', 'model.encoder.encoder.layer.1.attention.self.query.weight', 'model.encoder.encoder.layer.6.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.3.attention.self.query.bias', 'model.encoder.encoder.layer.11.attention.output.dense.weight', 'model.encoder.encoder.layer.11.attention.self.key.weight', 'model.encoder.encoder.layer.10.attention.self.query.bias', 'model.encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.output.dense.weight', 'model.encoder.encoder.layer.11.attention.output.dense.bias', 'model.encoder.encoder.layer.2.intermediate.dense.bias', 'model.encoder.embeddings.LayerNorm.bias', 'model.encoder.encoder.layer.6.attention.self.query.weight', 'model.encoder.encoder.layer.0.output.dense.bias', 'model.encoder.encoder.layer.2.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.value.weight', 'model.encoder.encoder.layer.6.attention.self.query.bias', 'model.encoder.encoder.layer.11.attention.self.query.bias', 'model.encoder.encoder.layer.0.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.5.output.dense.bias', 'model.encoder.encoder.layer.4.attention.self.key.bias', 'model.encoder.encoder.layer.6.attention.output.dense.weight', 'model.encoder.encoder.layer.9.attention.self.key.weight', 'model.encoder.encoder.layer.0.intermediate.dense.bias', 'model.encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.key.weight', 'model.encoder.encoder.layer.5.attention.self.key.weight', 'model.encoder.encoder.layer.6.attention.self.value.bias', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.intermediate.dense.bias', 'model.encoder.encoder.layer.5.output.LayerNorm.weight', 'model.encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.4.intermediate.dense.weight', 'model.encoder.encoder.layer.1.attention.output.dense.weight', 'model.encoder.encoder.layer.9.output.dense.bias', 'model.encoder.encoder.layer.7.intermediate.dense.weight', 'model.encoder.encoder.layer.4.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.self.key.weight', 'model.encoder.encoder.layer.0.attention.output.dense.weight', 'model.encoder.encoder.layer.1.attention.self.value.weight', 'model.encoder.encoder.layer.1.attention.self.key.weight', 'model.encoder.encoder.layer.0.attention.self.key.weight', 'model.encoder.encoder.layer.2.attention.self.key.weight', 'model.encoder.encoder.layer.4.attention.self.key.weight', 'model.encoder.encoder.layer.11.attention.self.key.bias', 'model.encoder.encoder.layer.6.attention.self.key.weight', 'model.encoder.encoder.layer.3.attention.output.dense.bias', 'model.encoder.embeddings.position_embeddings.weight', 'model.encoder.encoder.layer.1.attention.self.value.bias', 'model.encoder.encoder.layer.10.attention.output.dense.weight', 'model.encoder.encoder.layer.7.attention.self.key.bias', 'model.encoder.encoder.layer.0.attention.self.key.bias', 'model.encoder.encoder.layer.9.output.dense.weight', 'model.encoder.encoder.layer.3.attention.self.key.bias', 'model.encoder.encoder.layer.2.attention.output.dense.weight', 'model.encoder.encoder.layer.9.attention.self.value.weight', 'model.encoder.encoder.layer.10.output.LayerNorm.bias', 'model.encoder.encoder.layer.8.attention.self.query.weight', 'model.encoder.encoder.layer.9.attention.self.query.weight', 'model.encoder.encoder.layer.11.output.dense.weight', 'model.encoder.encoder.layer.3.output.LayerNorm.weight', 'model.encoder.encoder.layer.8.attention.self.query.bias', 'model.encoder.encoder.layer.8.attention.output.dense.weight', 'model.encoder.encoder.layer.4.intermediate.dense.bias', 'model.encoder.encoder.layer.9.attention.output.dense.weight', 'model.encoder.encoder.layer.2.output.dense.bias', 'model.encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.intermediate.dense.bias', 'model.encoder.encoder.layer.0.attention.self.query.weight', 'model.encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.9.output.LayerNorm.bias', 'model.encoder.encoder.layer.6.output.dense.weight', 'model.encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'model.encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.10.attention.self.value.bias', 'model.encoder.encoder.layer.5.attention.output.dense.bias', 'model.encoder.encoder.layer.2.attention.output.dense.bias', 'model.encoder.encoder.layer.3.output.LayerNorm.bias', 'model.encoder.embeddings.position_ids', 'model.encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.0.output.dense.weight', 'model.encoder.encoder.layer.1.output.LayerNorm.bias', 'model.encoder.encoder.layer.3.attention.self.query.weight', 'model.encoder.encoder.layer.11.attention.self.value.weight', 'model.encoder.encoder.layer.7.output.dense.weight', 'model.encoder.encoder.layer.4.output.LayerNorm.weight', 'model.encoder.encoder.layer.5.attention.self.value.bias', 'model.encoder.encoder.layer.2.attention.self.value.weight', 'model.encoder.encoder.layer.10.output.dense.weight', 'model.encoder.encoder.layer.0.attention.self.query.bias', 'model.encoder.encoder.layer.3.intermediate.dense.weight', 'model.encoder.encoder.layer.10.attention.self.value.weight', 'model.encoder.encoder.layer.8.attention.self.key.bias', 'model.encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'model.encoder.encoder.layer.7.attention.output.dense.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at fnlp/cpt-base and are newly initialized: ['model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.7.final_layer_norm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["定义 训练 args\n"],"metadata":{"id":"xq-PebFeFVQA"}},{"cell_type":"code","source":["!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR1Xn3xsHO5V","executionInfo":{"status":"ok","timestamp":1691546528269,"user_tz":-480,"elapsed":5583,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"c1d503df-fc12-4953-8f42-597f552d978c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/244.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.21.0\n"]}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","batch_size = 17\n","num_train_epochs = 8\n","# Show the training loss with every epoch\n","logging_steps = len(tokenized_datasets) // batch_size\n","model_name = check_model.split(\"/\")[-1]\n","\n","args = Seq2SeqTrainingArguments(\n","    output_dir=f\"{model_name}-finetuned-amazon-zh\",\n","    evaluation_strategy=\"epoch\",\n","    overwrite_output_dir=True,\n","    learning_rate=2e-5,  // 调整学习率效果不佳 原值: 5.6e-5\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=1,\n","    num_train_epochs=num_train_epochs,\n","    predict_with_generate=True,\n","    logging_steps=logging_steps,\n",")"],"metadata":{"id":"uahlvI4hFYZg","executionInfo":{"status":"ok","timestamp":1691550688704,"user_tz":-480,"elapsed":416,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"jE6AwiKmL4YT"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_JZc7v9MGzz","executionInfo":{"status":"ok","timestamp":1691546608914,"user_tz":-480,"elapsed":9285,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"93bc4ba5-8fbe-4b4a-949d-3325fbdbf3f9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]}]},{"cell_type":"code","source":["import nltk\n","\n","nltk.download(\"punkt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myMf59I0MJZ-","executionInfo":{"status":"ok","timestamp":1691546609977,"user_tz":-480,"elapsed":1077,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"84f4db62-2909-40c3-e4c0-0060f8939188"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","\n","\n","def three_sentence_summary(text):\n","    return \"\\n\".join(sent_tokenize(text)[:3])"],"metadata":{"id":"sp9VBLZYMNPr","executionInfo":{"status":"ok","timestamp":1691546609977,"user_tz":-480,"elapsed":6,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["官方文档测试函数"],"metadata":{"id":"awipUx6pk-aE"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"jgTsjgurnG3a","executionInfo":{"status":"ok","timestamp":1691546609978,"user_tz":-480,"elapsed":7,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def postprocess_text(preds, labels):\n","  preds = [pred.strip() for pred in preds]\n","  labels = [label.strip() for label in labels]\n","\n","  # rougeLSum expects newline after each sentence\n","  # preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n","  # labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n","\n","  return preds, labels"],"metadata":{"id":"OnbvcRcxlDvQ","executionInfo":{"status":"ok","timestamp":1691546609978,"user_tz":-480,"elapsed":7,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","def compute_metrics(eval_preds):\n","  preds, labels = eval_preds\n","  if isinstance(preds, tuple):\n","      preds = preds[0]\n","  # Replace -100s used for padding as we can't decode them\n","  preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n","  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","  # Some simple post-processing\n","  decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","  result = {k: round(v * 100, 4) for k, v in result.items()}\n","  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","  result[\"gen_len\"] = np.mean(prediction_lens)\n","  return result"],"metadata":{"id":"lnoJi54ec7hM","executionInfo":{"status":"ok","timestamp":1691546609979,"user_tz":-480,"elapsed":4,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"y_LtsPcwL8_E","executionInfo":{"status":"ok","timestamp":1691546610388,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = tokenized_datasets.remove_columns(\n","    zhSumTrainDataset.column_names\n",")\n","tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QdGUYY8FEs4","executionInfo":{"status":"ok","timestamp":1691546612640,"user_tz":-480,"elapsed":6,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"284b5e39-d97e-4d2f-9e36-75e3b322679e"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 5000\n","})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["tokenized_datasets1 = tokenized_datasets1.remove_columns(\n","    zhSumTestDataset.column_names\n",")\n","tokenized_datasets1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"419baXS7M5qm","executionInfo":{"status":"ok","timestamp":1691546613171,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"8a18f5fd-7296-4304-89d2-e535fb01325b"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 5000\n","})"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["生成 decoder_input_ids 给 decoder 模型使用"],"metadata":{"id":"jRtNkdmbMc7L"}},{"cell_type":"code","source":["features = [tokenized_datasets[i] for i in range(2)]\n","data_collator(features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LUoySLRLfPF","executionInfo":{"status":"ok","timestamp":1691546615586,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"04dc726e-5ef7-477e-a718-5d8ed1b6ffd5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  5007, 15134,  4932, 15128,  7710, 15134, 25818,  4909, 11009,\n","         15284, 20820, 25818,  6559, 15284, 15134,  8429, 12434,  5028,  8451,\n","          4896,  7189, 25807, 14112,  5954,  4909,  7807, 21002, 30878,  7710,\n","          5722, 15134, 12637,  6222,  5954, 25818, 21536, 20820,  5028, 25807,\n","          4909,  9185, 20447,  5007, 25807,   102],\n","        [  101,  9460,  4968,  6170, 19731, 15207, 21784, 12637, 11226, 25818,\n","          8485,  4896,  4938,  7514, 10861, 19673, 19731,  5028,  5879,  9223,\n","         23390, 17922, 25818,  4896, 15264,  8485, 10344,  5028,  7807,  5879,\n","          4938, 11567, 12257,  5028, 25818, 21784,  4909,  7807, 14788,  5028,\n","           102,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), 'labels': tensor([[  101,  5474, 20820,   102,  -100,  -100,  -100,  -100],\n","        [  101, 10036,  9191,  6438,  4896, 21022, 25807,   102]]), 'decoder_input_ids': tensor([[  102,   101,  5474, 20820,   102,     0,     0,     0],\n","        [  102,   101, 10036,  9191,  6438,  4896, 21022, 25807]])}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["features1 = [tokenized_datasets1[i] for i in range(2)]\n","data_collator(features1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCdZ_a-HM_Rm","executionInfo":{"status":"ok","timestamp":1691546618112,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"d8fec0f5-e8a9-4a6a-e90d-304900391721"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101, 21863, 21537,  5028,  9327, 22915, 10953, 23028, 25818, 11217,\n","          6433, 21562, 15478,  9970, 19705, 21536, 20820,  5028, 25818, 10931,\n","          7754, 21545, 10186,  5773,  5108,  3566, 41142, 25818,  5122,  5987,\n","          5100,  4909,  6350, 20469,  5140, 25818, 14417,  7221, 19916,  7807,\n","          7807, 20469,  5140,  5028, 25818,  6433, 11315,  9970,  8485, 10091,\n","         21498, 12403, 20494,  7697,  5965, 20893,  5028, 25818, 21497, 15254,\n","          5033, 25818, 20893,  5959,  6653,  7697,  5965,  5959,  6653, 25818,\n","         11217, 21991, 19916, 15134, 11009, 25818,  4909, 14788, 20437, 15284,\n","         15134, 20469, 20459,  5028, 25818,  4909, 14788,  9688, 21497,  8918,\n","          7710,  8453,  8270, 25818, 15241, 10371,  6372,  5905,  8485,  6402,\n","          5122,  5028, 25818, 10374, 18355, 17223,  7723,  8362, 25807, 25807,\n","           102],\n","        [  101, 23386,  8992, 10245, 17794, 25818, 10017,  5122, 20820, 10208,\n","          5959, 20486,  5028,  4896,  4907, 25818,  6302,  9342, 17794, 17716,\n","         14966, 25818,  8485, 14799, 20520,  5028, 21536, 20820,  3566,  6402,\n","         11009,  4954,  5086,  4968,  8922, 17213, 10412,  5058,  5028, 14799,\n","         20520, 25818, 16758, 17229,  5522,  5522, 10091,  9970, 15134, 14799,\n","         20520, 17223,  6377, 12865,  5028, 25807, 25807, 25807,  5048, 24145,\n","         21546, 19916, 17223,  9970,  4938, 20517, 12688, 25807, 25807, 25807,\n","         10931, 20510,  5028, 25818, 21498, 11009, 12282, 24188, 12865, 20838,\n","         17520, 15134,  5493, 12688, 25807, 25807, 25807,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[  101,  4909,  6830, 12258,   102,  -100,  -100,  -100,  -100,  -100,\n","          -100],\n","        [  101,  4954,  5086,  4968, 12282, 24188, 12865, 20838, 17520, 25807,\n","           102]]), 'decoder_input_ids': tensor([[  102,   101,  4909,  6830, 12258,   102,     0,     0,     0,     0,\n","             0],\n","        [  102,   101,  4954,  5086,  4968, 12282, 24188, 12865, 20838, 17520,\n","         25807]])}"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets,\n","    eval_dataset=tokenized_datasets1,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"gnbRJ6p4MnJp","executionInfo":{"status":"ok","timestamp":1691550701653,"user_tz":-480,"elapsed":392,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"31Al5ao3OnGg","outputId":"cdbd5917-fd36-474f-a163-f5500d0485f4","executionInfo":{"status":"ok","timestamp":1691553651295,"user_tz":-480,"elapsed":2945312,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2360' max='2360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2360/2360 49:03, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.407900</td>\n","      <td>3.264772</td>\n","      <td>0.130000</td>\n","      <td>0.020000</td>\n","      <td>0.120000</td>\n","      <td>0.130000</td>\n","      <td>7.009600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.275500</td>\n","      <td>3.317801</td>\n","      <td>0.173300</td>\n","      <td>0.013300</td>\n","      <td>0.169300</td>\n","      <td>0.169300</td>\n","      <td>7.522600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.150600</td>\n","      <td>3.401588</td>\n","      <td>0.168000</td>\n","      <td>0.013300</td>\n","      <td>0.166700</td>\n","      <td>0.165300</td>\n","      <td>7.717800</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.036200</td>\n","      <td>3.453164</td>\n","      <td>0.180000</td>\n","      <td>0.013300</td>\n","      <td>0.170000</td>\n","      <td>0.168000</td>\n","      <td>7.133800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.947900</td>\n","      <td>3.477561</td>\n","      <td>0.140000</td>\n","      <td>0.020000</td>\n","      <td>0.140000</td>\n","      <td>0.140000</td>\n","      <td>7.387400</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.864800</td>\n","      <td>3.509202</td>\n","      <td>0.148000</td>\n","      <td>0.020000</td>\n","      <td>0.140000</td>\n","      <td>0.144000</td>\n","      <td>7.333800</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.808500</td>\n","      <td>3.525378</td>\n","      <td>0.173300</td>\n","      <td>0.020000</td>\n","      <td>0.166700</td>\n","      <td>0.173300</td>\n","      <td>7.588800</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.766200</td>\n","      <td>3.530590</td>\n","      <td>0.140000</td>\n","      <td>0.020000</td>\n","      <td>0.140000</td>\n","      <td>0.140000</td>\n","      <td>7.584800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2360, training_loss=1.031290876259238, metrics={'train_runtime': 2944.86, 'train_samples_per_second': 13.583, 'train_steps_per_second': 0.801, 'total_flos': 4016045314778112.0, 'train_loss': 1.031290876259238, 'epoch': 8.0})"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"jIg6HGWT5XfM","executionInfo":{"status":"ok","timestamp":1691549559851,"user_tz":-480,"elapsed":184703,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"068e6718-27be-4844-82e6-6ca36bd8b7d4"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='334' max='334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [334/334 03:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.2537012100219727,\n"," 'eval_rouge1': 0.2,\n"," 'eval_rouge2': 0.02,\n"," 'eval_rougeL': 0.186,\n"," 'eval_rougeLsum': 0.186,\n"," 'eval_gen_len': 7.393,\n"," 'eval_runtime': 184.3031,\n"," 'eval_samples_per_second': 27.129,\n"," 'eval_steps_per_second': 1.812,\n"," 'epoch': 8.0}"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from transformers import pipeline\n","summarizer = pipeline(\"summarization\",model=\"/content/cpt-base-finetuned-amazon-zh/checkpoint-2500\")\n","articale = \"想吃麦片，看评论很多说这个好，买的，麦片和其他也差不多\"\n","summarizer(articale, max_length = 30, min_length = 5, do_sample=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZinBrktv6MNz","executionInfo":{"status":"ok","timestamp":1691549591550,"user_tz":-480,"elapsed":5550,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"154f5e3d-3d68-4254-cb84-e88e252d3d51"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'summary_text': '和 麦 片 的 不 一 样'}]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["def print_summary(idx):\n","    review = zhSumTestDataset[idx][\"review_body\"]\n","    title = zhSumTestDataset[idx][\"review_title\"]\n","    summary = summarizer(zhSumTestDataset[idx][\"review_body\"])[0][\"summary_text\"]\n","    print(f\"'>>> Review: {review}'\")\n","    print(f\"\\n'>>> Title: {title}'\")\n","    print(f\"\\n'>>> Summary: {summary}'\")"],"metadata":{"id":"igvDVDo-2k6c","executionInfo":{"status":"ok","timestamp":1691549639024,"user_tz":-480,"elapsed":583,"user":{"displayName":"li wolf","userId":"06883131957204073848"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print_summary(100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFLsFa9M2p1e","executionInfo":{"status":"ok","timestamp":1691549642080,"user_tz":-480,"elapsed":1406,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"9e364224-bf18-4aa3-f980-03bb2def275b"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["Your max_length is set to 128, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"]},{"output_type":"stream","name":"stdout","text":["'>>> Review: 商品差强人意，首先封面图片印刷不清与卖家提供图片不符…而且很贵物超所值，本身本子很小还贵比在外面文具店买的贵得多'\n","\n","'>>> Title: 不满意的一次网购'\n","\n","'>>> Summary: 商 品 质 量 很 差 ， 图 片 质 量 堪 忧'\n"]}]}]}