{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPajP+T88rvLVP4FGft5Fup"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 使用评价指标工具\n","训练和测试模型时往往需要计算不同的评价指标，如正确率、查准率、查全率、F1值等，具体指标往往和处理的数据和任务类型有关。  \n","分类问题评估指标：  \n","- 准确率 — Accuracy\n","- 精确率（差准率）- Precision\n","- 召回率（查全率）- Recall\n","- F1分数\n","- ROC曲线\n","- AUC曲线  \n","\n","回归问题评估指标：\n","- MAE\n","- MSE\n","\n","huggingface 提供了评价指标工具，计算结果隐藏。\n","## 1. 使用评价指标工具\n","### 1. 列出可用的评价指标\n","使用 list_metrics() 函数列出所有可用的评价指标"],"metadata":{"id":"6nsN_tpPoMoR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKKEugdKn_4V","executionInfo":{"status":"ok","timestamp":1690970893247,"user_tz":-480,"elapsed":14895,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"c823d1c4-bced-4cf9-ffdb-0d6c62645535"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.14.2 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 xxhash-3.3.0\n"]}],"source":["# !pip install datasets"]},{"cell_type":"code","source":["from datasets import list_metrics\n","metrics_list = list_metrics()\n","len(metrics_list), metrics_list[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2cFJOqauLa9","executionInfo":{"status":"ok","timestamp":1690970977877,"user_tz":-480,"elapsed":511,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"cc87ff97-f4df-46e2-d7ff-17bfdfbab203"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-0404ed0be804>:2: FutureWarning: list_metrics is deprecated and will be removed in the next major version of datasets. Use 'evaluate.list_evaluation_modules' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics_list = list_metrics()\n"]},{"output_type":"execute_result","data":{"text/plain":["(121, ['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score'])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### 2. 加载一个评价指标\n","利用 load_metric() 函数，评价指标往往会对应的数据集配套使用，下面以 glue 数据集的 mrpc 子集位例:  \n","注意并不是每一个数据集都有评价指标，实际应用时应根据具体情况选择合适的评价指标。"],"metadata":{"id":"x3pppiOnu1ve"}},{"cell_type":"code","source":["from datasets import load_metric\n","metric = load_metric('glue','mrpc')\n","print(metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY_J1SHjvWNm","executionInfo":{"status":"ok","timestamp":1690972274095,"user_tz":-480,"elapsed":1444,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"97621446-b56a-4119-96e7-a805650a9451"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n","Compute GLUE evaluation metric associated to each GLUE dataset.\n","Args:\n","    predictions: list of predictions to score.\n","        Each translation should be tokenized into a list of tokens.\n","    references: list of lists of references for each translation.\n","        Each reference should be tokenized into a list of tokens.\n","Returns: depending on the GLUE subset, one or several of:\n","    \"accuracy\": Accuracy\n","    \"f1\": F1 score\n","    \"pearson\": Pearson Correlation\n","    \"spearmanr\": Spearman Correlation\n","    \"matthews_correlation\": Matthew Correlation\n","Examples:\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0, 'f1': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n","    >>> references = [0., 1., 2., 3., 4., 5.]\n","    >>> predictions = [0., 1., 2., 3., 4., 5.]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n","    {'pearson': 1.0, 'spearmanr': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'cola')\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'matthews_correlation': 1.0}\n","\"\"\", stored examples: 0)\n"]}]},{"cell_type":"markdown","source":["### 3. 获取评价指标的使用说明\n","评价指标的 inputs_description 属性为一段文本，描述评价指标的使用方法，不同的评价指标输入往往是不同的。"],"metadata":{"id":"aHO-WwIvuI7Z"}},{"cell_type":"code","source":["print(metric.inputs_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXgjhJ5-0CHI","executionInfo":{"status":"ok","timestamp":1690972497138,"user_tz":-480,"elapsed":3,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"6f9d054d-a813-43f5-e265-b5693a0d60e4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Compute GLUE evaluation metric associated to each GLUE dataset.\n","Args:\n","    predictions: list of predictions to score.\n","        Each translation should be tokenized into a list of tokens.\n","    references: list of lists of references for each translation.\n","        Each reference should be tokenized into a list of tokens.\n","Returns: depending on the GLUE subset, one or several of:\n","    \"accuracy\": Accuracy\n","    \"f1\": F1 score\n","    \"pearson\": Pearson Correlation\n","    \"spearmanr\": Spearman Correlation\n","    \"matthews_correlation\": Matthew Correlation\n","Examples:\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0, 'f1': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n","    >>> references = [0., 1., 2., 3., 4., 5.]\n","    >>> predictions = [0., 1., 2., 3., 4., 5.]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n","    {'pearson': 1.0, 'spearmanr': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'cola')\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'matthews_correlation': 1.0}\n","\n"]}]},{"cell_type":"markdown","source":["### 4. 计算评价指标\n"],"metadata":{"id":"YWp7oXP20tsX"}},{"cell_type":"code","source":["glue_metric = load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","references = [0, 1, 0, 1]  # 标记\n","predictions = [0, 1, 1, 0]  # 模型预测结果\n","results = glue_metric.compute(predictions=predictions, references=references)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hM0R0LF02xF","executionInfo":{"status":"ok","timestamp":1690972799897,"user_tz":-480,"elapsed":1583,"user":{"displayName":"li wolf","userId":"06883131957204073848"}},"outputId":"2d25bff2-d0b4-49c5-d182-2b67c39a4481"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.5, 'f1': 0.5}\n"]}]}]}